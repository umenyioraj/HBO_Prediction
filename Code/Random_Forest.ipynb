{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa5689-261b-447d-b489-81dc342bc6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9991304347826087\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       1.00      1.00      1.00       613\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "                Feature  Importance\n",
      "0    imdbAverageRating    0.789962\n",
      "1         imdbNumVotes    0.071471\n",
      "2          releaseYear    0.028112\n",
      "3        num_countries    0.023687\n",
      "4         type_encoded    0.019773\n",
      "38             Unknown    0.007988\n",
      "14               Drama    0.007611\n",
      "10           Biography    0.007008\n",
      "13         Documentary    0.005083\n",
      "11              Comedy    0.004190\n",
      "20              Horror    0.003599\n",
      "8            Adventure    0.003277\n",
      "9            Animation    0.003007\n",
      "5               Action    0.002864\n",
      "12               Crime    0.002583\n",
      "37            Thriller    0.001957\n",
      "19             History    0.001790\n",
      "26             Reality    0.001705\n",
      "16             Fantasy    0.001698\n",
      "28             Romance    0.001695\n",
      "24             Mystery    0.001535\n",
      "27          Reality-TV    0.001396\n",
      "15              Family    0.001310\n",
      "29              Sci-Fi    0.001122\n",
      "32               Short    0.001034\n",
      "33               Sport    0.000836\n",
      "39                 War    0.000671\n",
      "18           Game-Show    0.000648\n",
      "22               Music    0.000584\n",
      "34            TV Movie    0.000342\n",
      "36           Talk-Show    0.000318\n",
      "21                Kids    0.000301\n",
      "23             Musical    0.000284\n",
      "35                Talk    0.000169\n",
      "40             Western    0.000123\n",
      "25                News    0.000108\n",
      "6   Action & Adventure    0.000066\n",
      "30    Sci-Fi & Fantasy    0.000051\n",
      "7                Adult    0.000035\n",
      "31     Science Fiction    0.000009\n",
      "17           Film-Noir    0.000000\n",
      "Index(['title', 'type', 'genres', 'releaseYear', 'imdbId', 'imdbAverageRating',\n",
      "       'imdbNumVotes', 'availableCountries'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73], got [1.5 1.6 2.  2.2 2.4 2.5 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9\n 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.  5.1 5.2 5.3 5.4 5.5 5.6 5.7\n 5.8 5.9 6.  6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.  7.1 7.2 7.3 7.4 7.5\n 7.6 7.7 7.8 7.9 8.  8.1 8.2 8.3 8.4 8.5 8.6 8.7 8.8 8.9 9.  9.1 9.2 9.3\n 9.4 nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     97\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\umeny\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\umeny\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1490\u001b[0m ):\n\u001b[1;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73], got [1.5 1.6 2.  2.2 2.4 2.5 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9\n 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.  5.1 5.2 5.3 5.4 5.5 5.6 5.7\n 5.8 5.9 6.  6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.  7.1 7.2 7.3 7.4 7.5\n 7.6 7.7 7.8 7.9 8.  8.1 8.2 8.3 8.4 8.5 8.6 8.7 8.8 8.9 9.  9.1 9.2 9.3\n 9.4 nan]"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "df['retention_decision'] = (df['imdbAverageRating'] > 6.5).astype(int)\n",
    "\n",
    "# Impute numerical columns with the mean\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "numerical_features = ['imdbAverageRating', 'imdbNumVotes', 'releaseYear']\n",
    "df[numerical_features] = num_imputer.fit_transform(df[numerical_features])\n",
    "\n",
    "# Impute categorical columns with the most frequent value\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['type'] = cat_imputer.fit_transform(df[['type']]).ravel()\n",
    "\n",
    "df['genres'] = df['genres'].fillna('Unknown')\n",
    "df['availableCountries'] = df['availableCountries'].fillna('')\n",
    "\n",
    "# Feature Engineering\n",
    "df['num_countries'] = df['availableCountries'].apply(lambda x: len(x.split(', ')))\n",
    "genres = df['genres'].str.get_dummies(sep=', ')\n",
    "df['type_encoded'] = (df['type'] == 'movie').astype(int)\n",
    "\n",
    "features = pd.concat([\n",
    "    df[['imdbAverageRating', 'imdbNumVotes', 'releaseYear', 'num_countries', 'type_encoded']], \n",
    "    genres\n",
    "], axis=1)\n",
    "target = df['retention_decision']\n",
    "\n",
    "# Step 3: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 6: Feature Importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = features.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importances:\\n\", importance_df)\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# # Initialize the Random Forest Classifier\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Perform 5-Fold Cross-Validation\n",
    "# cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Print Results\n",
    "# print(\"Cross-Validation Scores for Each Fold:\", cv_scores)\n",
    "# print(\"Mean Accuracy:\", cv_scores.mean())\n",
    "# print(\"Standard Deviation:\", cv_scores.std())\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Inspect the columns to find the correct target\n",
    "print(df.columns)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['imdbId', 'type', 'genres', 'availableCountries'])  # Drop unnecessary columns\n",
    "y = df['imdbAverageRating']  #Replace 'retained' with the actual target column name\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importances\n",
    "print(\"Feature Importances:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858f418-b9ca-4906-8d22-32d6ffa8333d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
